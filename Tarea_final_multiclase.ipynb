{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Maintenance\n",
        "\n",
        "\n",
        "Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in the industry to the best of our knowledge.\n",
        "\n",
        "The dataset consists of 10 000 data points stored as rows with 14 features in columns\n",
        "\n",
        "\n",
        "\n",
        "*   UID: unique identifier ranging from 1 to 10000\n",
        "*   ProductID: consisting of a letter L, M, or H for low (50% of all products),\n",
        "medium (30%), and high (20%) as product quality variants and a variant-specific serial number\n",
        "\n",
        "\n",
        "\n",
        "*   Air temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
        "*   Process temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Rotational speed [rpm]: calculated from powepower of 2860 W, overlaid with a normally distributed noise\n",
        "*   torque [Nm]: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.\n",
        "\n",
        "\n",
        "\n",
        "*   Tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process.\n",
        "\n",
        "A 'machine failure' label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true.\n",
        "Important : There are two Targets - Do not make the mistake of using one of them as feature, as it will lead to leakage.\n",
        "\n",
        "\n",
        "\n",
        "*   Target : Failure or Not\n",
        "*   Failure Type : Type of Failure\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3nC6zrlc-vUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "QXjI55lX9RFL",
        "outputId": "e31bc7d7-6d1d-4f00-e9ce-aeeb84d5d756"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'label_binarize' from 'sklearn.metrics' (/usr/local/lib/python3.11/dist-packages/sklearn/metrics/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-3261541441>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from sklearn.metrics import(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatthews_corrcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'label_binarize' from 'sklearn.metrics' (/usr/local/lib/python3.11/dist-packages/sklearn/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import(\n",
        "    precision_score, recall_score, f1_score, balanced_accuracy_score,\n",
        "    confusion_matrix, matthews_corrcoef, roc_auc_score, label_binarize\n",
        ")\n",
        "import numpy as np\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semilla = 7\n",
        "df = pd.read_csv('predictive_maintenance.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "A3TCCuhy-T3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LE = LabelEncoder()\n",
        "df['Type'] = LE.fit_transform(df['Type'])\n",
        "df['Type'].value_counts()"
      ],
      "metadata": {
        "id": "pRs3MKiTGRE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Failure Type'].value_counts()"
      ],
      "metadata": {
        "id": "nP0QWGprOgzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar características de la etiqueta\n",
        "\n",
        "X = df.drop(columns = ['UDI', 'Product ID', 'Failure Type'])\n",
        "Y = df['Failure Type']"
      ],
      "metadata": {
        "id": "r8kRNfXJIKj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método de validación\n",
        "\n",
        "Validación cruzada estratificada\n",
        "\n",
        "* Aplicación de smote para cada Fold"
      ],
      "metadata": {
        "id": "fSjhMkCcIkWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matriz(y_test, y_pred):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  print(\"-\"*30)\n",
        "  print(\"Matriz de confusión:\")\n",
        "  print(f\"{tp:>3} {fn:>3}\")\n",
        "  print(f\"{fp:>3} {tn:>3}\")"
      ],
      "metadata": {
        "id": "j9m5EipGcF3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algoritmo Euclidiano\n"
      ],
      "metadata": {
        "id": "U2YvnMNCXCM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_medidas(y_true, y_pred, y_prob):\n",
        "  recall = recall_score(y_true, y_pred, average = 'macro')\n",
        "  specificity = recall_score(y_true, y_pred, pos_label = 0, average='macro')\n",
        "  b_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred, average = 'macro')\n",
        "  f1 = f1_score(y_true, y_pred, average = 'macro')\n",
        "  mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "  # ROC-AUC\n",
        "  classes = np.unique(y_true)\n",
        "  y_true_bin = label_binarize(y_true, classes = classes)\n",
        "  roc_auc_macro = roc_auc_score(y_true_bin, y_prob, average = 'macro', multiclass = 'ovr')\n",
        "\n",
        "  metrics_table = [\n",
        "      ['Recall', recall],\n",
        "      ['Specificity', specificity],\n",
        "      ['Balanced Accuracy', b_acc],\n",
        "      ['Precision', precision],\n",
        "      ['F1 Score', f1],\n",
        "      ['MCC', mcc],\n",
        "      ['ROC-AUC', roc_auc_macro]\n",
        "  ]\n",
        "\n",
        "  print(tabulate(metrics_table, ['Medidas', 'Valor'], floatfmt = '.4f', tablefmt = 'plain'))"
      ],
      "metadata": {
        "id": "UwTpTf-PfPiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = semilla)\n",
        "y_true_total = []\n",
        "y_pred_total = []\n",
        "y_proba_total = []\n",
        "\n",
        "for train_idx, test_idx in kf.split(X, Y):\n",
        "  x_train, x_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "  y_train, y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
        "\n",
        "  smote = SMOTE(random_state = semilla)\n",
        "  x_train, y_train = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors = 1, metric = 'euclidean')\n",
        "  model.fit(x_train, y_train)\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_prob = model.predict_proba(x_test)\n",
        "\n",
        "  y_true_total.extend(y_test)\n",
        "  y_pred_total.extend(y_pred)\n",
        "  y_proba_total.extend(y_prob)\n",
        "\n",
        "macro_medidas(y_true_total, y_pred_total, y_proba_total)"
      ],
      "metadata": {
        "id": "gH9HkaBGXIqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}