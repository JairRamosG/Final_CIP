{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR0kROzNGGs7"
      },
      "source": [
        "# Oil Spill Dataset\n",
        "\n",
        "\n",
        "The dataset was developed by starting with satellite images of the ocean, some of which contain an oil spill and some that do not.\n",
        "Images were split into sections and processed using computer vision algorithms to provide a vector of features to describe the contents of the image section or patch.\n",
        "The task is, given a vector that describes the contents of a patch of a satellite image, then predicts whether the patch contains an oil spill or not, e.g. from the illegal or accidental dumping of oil in the ocean.\n",
        "\n",
        "There are two classes and the goal is to distinguish between spill and non-spill using the features for a given ocean patch.\n",
        "\n",
        "Non-Spill: negative case, or majority class --> [0]\n",
        "\n",
        "Oil Spill: positive case, or minority class --> [1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3m2tzLkF5Bt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "NemWhaTDF8m2",
        "outputId": "c79e47b5-21c7-459a-bd47-2bd5e6661ab2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>f_10</th>\n",
              "      <th>...</th>\n",
              "      <th>f_41</th>\n",
              "      <th>f_42</th>\n",
              "      <th>f_43</th>\n",
              "      <th>f_44</th>\n",
              "      <th>f_45</th>\n",
              "      <th>f_46</th>\n",
              "      <th>f_47</th>\n",
              "      <th>f_48</th>\n",
              "      <th>f_49</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>85.90</td>\n",
              "      <td>171.80</td>\n",
              "      <td>72</td>\n",
              "      <td>81000</td>\n",
              "      <td>54.10</td>\n",
              "      <td>9.18</td>\n",
              "      <td>884.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>...</td>\n",
              "      <td>484.66</td>\n",
              "      <td>90.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>49.30</td>\n",
              "      <td>8.98</td>\n",
              "      <td>1</td>\n",
              "      <td>6226.34</td>\n",
              "      <td>65.59</td>\n",
              "      <td>6.56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>12</td>\n",
              "      <td>13.33</td>\n",
              "      <td>483.92</td>\n",
              "      <td>34</td>\n",
              "      <td>97200</td>\n",
              "      <td>73.33</td>\n",
              "      <td>5.47</td>\n",
              "      <td>868.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>402.49</td>\n",
              "      <td>127.28</td>\n",
              "      <td>95.46</td>\n",
              "      <td>63.64</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0</td>\n",
              "      <td>5509.43</td>\n",
              "      <td>65.98</td>\n",
              "      <td>6.02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>130</td>\n",
              "      <td>58</td>\n",
              "      <td>1113.98</td>\n",
              "      <td>965.40</td>\n",
              "      <td>55</td>\n",
              "      <td>145000</td>\n",
              "      <td>38.57</td>\n",
              "      <td>7.48</td>\n",
              "      <td>2310.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>430.12</td>\n",
              "      <td>320.16</td>\n",
              "      <td>171.41</td>\n",
              "      <td>92.94</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0</td>\n",
              "      <td>3622.84</td>\n",
              "      <td>65.93</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2339</td>\n",
              "      <td>1537.68</td>\n",
              "      <td>1633.02</td>\n",
              "      <td>45</td>\n",
              "      <td>5847500</td>\n",
              "      <td>38.13</td>\n",
              "      <td>9.29</td>\n",
              "      <td>22110.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>3959.80</td>\n",
              "      <td>2404.16</td>\n",
              "      <td>1530.38</td>\n",
              "      <td>659.67</td>\n",
              "      <td>2.59</td>\n",
              "      <td>0</td>\n",
              "      <td>4732.04</td>\n",
              "      <td>66.34</td>\n",
              "      <td>7.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>139</td>\n",
              "      <td>14</td>\n",
              "      <td>37.57</td>\n",
              "      <td>304.43</td>\n",
              "      <td>35</td>\n",
              "      <td>113400</td>\n",
              "      <td>55.07</td>\n",
              "      <td>7.22</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>0.13</td>\n",
              "      <td>...</td>\n",
              "      <td>402.49</td>\n",
              "      <td>254.56</td>\n",
              "      <td>63.64</td>\n",
              "      <td>127.28</td>\n",
              "      <td>6.32</td>\n",
              "      <td>0</td>\n",
              "      <td>2963.85</td>\n",
              "      <td>65.75</td>\n",
              "      <td>6.28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>220</td>\n",
              "      <td>264.28</td>\n",
              "      <td>560.03</td>\n",
              "      <td>167</td>\n",
              "      <td>1782000</td>\n",
              "      <td>45.51</td>\n",
              "      <td>13.98</td>\n",
              "      <td>11909.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>...</td>\n",
              "      <td>3623.55</td>\n",
              "      <td>655.21</td>\n",
              "      <td>357.20</td>\n",
              "      <td>157.02</td>\n",
              "      <td>10.14</td>\n",
              "      <td>1</td>\n",
              "      <td>10769.64</td>\n",
              "      <td>66.17</td>\n",
              "      <td>6.74</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>192</td>\n",
              "      <td>162</td>\n",
              "      <td>1178.77</td>\n",
              "      <td>993.60</td>\n",
              "      <td>99</td>\n",
              "      <td>405000</td>\n",
              "      <td>34.73</td>\n",
              "      <td>6.88</td>\n",
              "      <td>4340.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>1265.90</td>\n",
              "      <td>509.90</td>\n",
              "      <td>227.86</td>\n",
              "      <td>140.98</td>\n",
              "      <td>5.56</td>\n",
              "      <td>0</td>\n",
              "      <td>5606.99</td>\n",
              "      <td>65.95</td>\n",
              "      <td>7.42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>1245.49</td>\n",
              "      <td>1268.11</td>\n",
              "      <td>151</td>\n",
              "      <td>85781</td>\n",
              "      <td>33.87</td>\n",
              "      <td>14.88</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>0.44</td>\n",
              "      <td>...</td>\n",
              "      <td>469.87</td>\n",
              "      <td>251.56</td>\n",
              "      <td>129.70</td>\n",
              "      <td>75.38</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0</td>\n",
              "      <td>7610.61</td>\n",
              "      <td>36.85</td>\n",
              "      <td>15.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>98</td>\n",
              "      <td>92</td>\n",
              "      <td>1401.25</td>\n",
              "      <td>933.60</td>\n",
              "      <td>93</td>\n",
              "      <td>230000</td>\n",
              "      <td>43.38</td>\n",
              "      <td>5.99</td>\n",
              "      <td>3430.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>...</td>\n",
              "      <td>951.31</td>\n",
              "      <td>300.00</td>\n",
              "      <td>176.32</td>\n",
              "      <td>88.77</td>\n",
              "      <td>5.40</td>\n",
              "      <td>0</td>\n",
              "      <td>8586.62</td>\n",
              "      <td>65.98</td>\n",
              "      <td>7.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>33</td>\n",
              "      <td>30.55</td>\n",
              "      <td>385.03</td>\n",
              "      <td>51</td>\n",
              "      <td>267300</td>\n",
              "      <td>72.61</td>\n",
              "      <td>16.89</td>\n",
              "      <td>1482.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>...</td>\n",
              "      <td>576.28</td>\n",
              "      <td>381.84</td>\n",
              "      <td>305.47</td>\n",
              "      <td>69.71</td>\n",
              "      <td>1.89</td>\n",
              "      <td>0</td>\n",
              "      <td>9412.12</td>\n",
              "      <td>65.85</td>\n",
              "      <td>6.18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>204</td>\n",
              "      <td>11</td>\n",
              "      <td>7.73</td>\n",
              "      <td>235.73</td>\n",
              "      <td>135</td>\n",
              "      <td>89100</td>\n",
              "      <td>61.82</td>\n",
              "      <td>12.24</td>\n",
              "      <td>831.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>254.56</td>\n",
              "      <td>254.56</td>\n",
              "      <td>127.28</td>\n",
              "      <td>180.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0</td>\n",
              "      <td>3782.68</td>\n",
              "      <td>65.65</td>\n",
              "      <td>6.26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>14</td>\n",
              "      <td>78</td>\n",
              "      <td>266.33</td>\n",
              "      <td>188.99</td>\n",
              "      <td>121</td>\n",
              "      <td>631800</td>\n",
              "      <td>48.53</td>\n",
              "      <td>12.04</td>\n",
              "      <td>4605.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>1127.70</td>\n",
              "      <td>649.00</td>\n",
              "      <td>331.59</td>\n",
              "      <td>185.94</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0</td>\n",
              "      <td>13669.58</td>\n",
              "      <td>65.68</td>\n",
              "      <td>7.11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>43</td>\n",
              "      <td>92</td>\n",
              "      <td>1688.79</td>\n",
              "      <td>1245.62</td>\n",
              "      <td>35</td>\n",
              "      <td>230000</td>\n",
              "      <td>36.89</td>\n",
              "      <td>6.17</td>\n",
              "      <td>2030.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>...</td>\n",
              "      <td>790.57</td>\n",
              "      <td>360.56</td>\n",
              "      <td>218.54</td>\n",
              "      <td>103.73</td>\n",
              "      <td>3.62</td>\n",
              "      <td>0</td>\n",
              "      <td>3668.15</td>\n",
              "      <td>66.18</td>\n",
              "      <td>7.98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>150</td>\n",
              "      <td>112</td>\n",
              "      <td>821.42</td>\n",
              "      <td>999.41</td>\n",
              "      <td>1</td>\n",
              "      <td>280000</td>\n",
              "      <td>41.11</td>\n",
              "      <td>5.92</td>\n",
              "      <td>2980.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>...</td>\n",
              "      <td>900.00</td>\n",
              "      <td>400.00</td>\n",
              "      <td>275.00</td>\n",
              "      <td>69.13</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0</td>\n",
              "      <td>4514.70</td>\n",
              "      <td>65.91</td>\n",
              "      <td>7.02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>34</td>\n",
              "      <td>18</td>\n",
              "      <td>16.00</td>\n",
              "      <td>384.28</td>\n",
              "      <td>125</td>\n",
              "      <td>145800</td>\n",
              "      <td>53.22</td>\n",
              "      <td>9.37</td>\n",
              "      <td>1535.0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>...</td>\n",
              "      <td>649.00</td>\n",
              "      <td>127.28</td>\n",
              "      <td>106.07</td>\n",
              "      <td>51.96</td>\n",
              "      <td>6.12</td>\n",
              "      <td>1</td>\n",
              "      <td>8654.28</td>\n",
              "      <td>65.85</td>\n",
              "      <td>6.13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>454.66</td>\n",
              "      <td>624.00</td>\n",
              "      <td>155</td>\n",
              "      <td>234900</td>\n",
              "      <td>55.83</td>\n",
              "      <td>16.89</td>\n",
              "      <td>1858.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>...</td>\n",
              "      <td>768.96</td>\n",
              "      <td>284.60</td>\n",
              "      <td>170.58</td>\n",
              "      <td>61.45</td>\n",
              "      <td>4.51</td>\n",
              "      <td>0</td>\n",
              "      <td>22517.01</td>\n",
              "      <td>66.33</td>\n",
              "      <td>7.28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3</td>\n",
              "      <td>183</td>\n",
              "      <td>474.38</td>\n",
              "      <td>309.86</td>\n",
              "      <td>135</td>\n",
              "      <td>1482300</td>\n",
              "      <td>54.20</td>\n",
              "      <td>18.60</td>\n",
              "      <td>9294.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>...</td>\n",
              "      <td>2672.86</td>\n",
              "      <td>636.40</td>\n",
              "      <td>345.47</td>\n",
              "      <td>145.92</td>\n",
              "      <td>7.74</td>\n",
              "      <td>0</td>\n",
              "      <td>28174.27</td>\n",
              "      <td>65.92</td>\n",
              "      <td>7.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>34</td>\n",
              "      <td>65</td>\n",
              "      <td>1213.38</td>\n",
              "      <td>1683.72</td>\n",
              "      <td>24</td>\n",
              "      <td>91406</td>\n",
              "      <td>24.06</td>\n",
              "      <td>7.73</td>\n",
              "      <td>1227.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>9122.65</td>\n",
              "      <td>36.86</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>118</td>\n",
              "      <td>96</td>\n",
              "      <td>920.20</td>\n",
              "      <td>640.12</td>\n",
              "      <td>41</td>\n",
              "      <td>240000</td>\n",
              "      <td>31.50</td>\n",
              "      <td>7.44</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>...</td>\n",
              "      <td>851.47</td>\n",
              "      <td>282.84</td>\n",
              "      <td>184.94</td>\n",
              "      <td>84.35</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0</td>\n",
              "      <td>27836.68</td>\n",
              "      <td>65.77</td>\n",
              "      <td>7.29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>31.23</td>\n",
              "      <td>412.77</td>\n",
              "      <td>62</td>\n",
              "      <td>178200</td>\n",
              "      <td>49.77</td>\n",
              "      <td>8.49</td>\n",
              "      <td>1985.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>...</td>\n",
              "      <td>1049.57</td>\n",
              "      <td>127.28</td>\n",
              "      <td>25.46</td>\n",
              "      <td>53.67</td>\n",
              "      <td>41.23</td>\n",
              "      <td>1</td>\n",
              "      <td>2312.51</td>\n",
              "      <td>65.89</td>\n",
              "      <td>6.15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>50</td>\n",
              "      <td>51</td>\n",
              "      <td>1064.12</td>\n",
              "      <td>432.69</td>\n",
              "      <td>51</td>\n",
              "      <td>127500</td>\n",
              "      <td>31.61</td>\n",
              "      <td>5.26</td>\n",
              "      <td>2210.0</td>\n",
              "      <td>0.17</td>\n",
              "      <td>...</td>\n",
              "      <td>1140.18</td>\n",
              "      <td>70.71</td>\n",
              "      <td>35.36</td>\n",
              "      <td>36.38</td>\n",
              "      <td>32.25</td>\n",
              "      <td>1</td>\n",
              "      <td>6946.12</td>\n",
              "      <td>65.67</td>\n",
              "      <td>7.48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>99</td>\n",
              "      <td>56</td>\n",
              "      <td>1732.82</td>\n",
              "      <td>1557.52</td>\n",
              "      <td>8</td>\n",
              "      <td>140000</td>\n",
              "      <td>38.32</td>\n",
              "      <td>4.53</td>\n",
              "      <td>1280.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>509.90</td>\n",
              "      <td>353.55</td>\n",
              "      <td>215.77</td>\n",
              "      <td>75.97</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0</td>\n",
              "      <td>3664.41</td>\n",
              "      <td>66.33</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>27</td>\n",
              "      <td>91</td>\n",
              "      <td>982.67</td>\n",
              "      <td>899.04</td>\n",
              "      <td>49</td>\n",
              "      <td>127968</td>\n",
              "      <td>27.27</td>\n",
              "      <td>9.12</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>0.33</td>\n",
              "      <td>...</td>\n",
              "      <td>850.18</td>\n",
              "      <td>265.17</td>\n",
              "      <td>96.93</td>\n",
              "      <td>90.13</td>\n",
              "      <td>8.77</td>\n",
              "      <td>0</td>\n",
              "      <td>12460.92</td>\n",
              "      <td>36.64</td>\n",
              "      <td>15.26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>137</td>\n",
              "      <td>51</td>\n",
              "      <td>111.84</td>\n",
              "      <td>1653.65</td>\n",
              "      <td>168</td>\n",
              "      <td>127500</td>\n",
              "      <td>44.43</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>509.90</td>\n",
              "      <td>316.23</td>\n",
              "      <td>136.62</td>\n",
              "      <td>67.36</td>\n",
              "      <td>3.73</td>\n",
              "      <td>0</td>\n",
              "      <td>27403.81</td>\n",
              "      <td>66.16</td>\n",
              "      <td>5.98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11</td>\n",
              "      <td>1115</td>\n",
              "      <td>1290.31</td>\n",
              "      <td>636.15</td>\n",
              "      <td>66</td>\n",
              "      <td>2787500</td>\n",
              "      <td>30.37</td>\n",
              "      <td>8.69</td>\n",
              "      <td>13830.0</td>\n",
              "      <td>0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>3447.10</td>\n",
              "      <td>1411.56</td>\n",
              "      <td>824.28</td>\n",
              "      <td>212.62</td>\n",
              "      <td>4.18</td>\n",
              "      <td>0</td>\n",
              "      <td>7016.73</td>\n",
              "      <td>65.80</td>\n",
              "      <td>7.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    f_1   f_2      f_3      f_4  f_5      f_6    f_7    f_8      f_9  f_10  \\\n",
              "0   120    10    85.90   171.80   72    81000  54.10   9.18    884.0  0.17   \n",
              "1    82    12    13.33   483.92   34    97200  73.33   5.47    868.0  0.07   \n",
              "2   130    58  1113.98   965.40   55   145000  38.57   7.48   2310.0  0.19   \n",
              "3     3  2339  1537.68  1633.02   45  5847500  38.13   9.29  22110.0  0.24   \n",
              "4   139    14    37.57   304.43   35   113400  55.07   7.22   1011.0  0.13   \n",
              "5     4   220   264.28   560.03  167  1782000  45.51  13.98  11909.0  0.31   \n",
              "6   192   162  1178.77   993.60   99   405000  34.73   6.88   4340.0  0.20   \n",
              "7    61    61  1245.49  1268.11  151    85781  33.87  14.88   1302.0  0.44   \n",
              "8    98    92  1401.25   933.60   93   230000  43.38   5.99   3430.0  0.14   \n",
              "9    15    33    30.55   385.03   51   267300  72.61  16.89   1482.0  0.23   \n",
              "10  204    11     7.73   235.73  135    89100  61.82  12.24    831.0  0.20   \n",
              "11   14    78   266.33   188.99  121   631800  48.53  12.04   4605.0  0.25   \n",
              "12   43    92  1688.79  1245.62   35   230000  36.89   6.17   2030.0  0.17   \n",
              "13  150   112   821.42   999.41    1   280000  41.11   5.92   2980.0  0.14   \n",
              "14   34    18    16.00   384.28  125   145800  53.22   9.37   1535.0  0.18   \n",
              "15   12    29   454.66   624.00  155   234900  55.83  16.89   1858.0  0.30   \n",
              "16    3   183   474.38   309.86  135  1482300  54.20  18.60   9294.0  0.34   \n",
              "17   34    65  1213.38  1683.72   24    91406  24.06   7.73   1227.0  0.32   \n",
              "18  118    96   920.20   640.12   41   240000  31.50   7.44   2370.0  0.24   \n",
              "19   16    22    31.23   412.77   62   178200  49.77   8.49   1985.0  0.17   \n",
              "20   50    51  1064.12   432.69   51   127500  31.61   5.26   2210.0  0.17   \n",
              "21   99    56  1732.82  1557.52    8   140000  38.32   4.53   1280.0  0.12   \n",
              "22   27    91   982.67   899.04   49   127968  27.27   9.12   2370.0  0.33   \n",
              "23  137    51   111.84  1653.65  168   127500  44.43   2.80   1680.0  0.06   \n",
              "24   11  1115  1290.31   636.15   66  2787500  30.37   8.69  13830.0  0.29   \n",
              "\n",
              "    ...     f_41     f_42     f_43    f_44   f_45  f_46      f_47   f_48  \\\n",
              "0   ...   484.66    90.00    54.00   49.30   8.98     1   6226.34  65.59   \n",
              "1   ...   402.49   127.28    95.46   63.64   4.22     0   5509.43  65.98   \n",
              "2   ...   430.12   320.16   171.41   92.94   2.51     0   3622.84  65.93   \n",
              "3   ...  3959.80  2404.16  1530.38  659.67   2.59     0   4732.04  66.34   \n",
              "4   ...   402.49   254.56    63.64  127.28   6.32     0   2963.85  65.75   \n",
              "5   ...  3623.55   655.21   357.20  157.02  10.14     1  10769.64  66.17   \n",
              "6   ...  1265.90   509.90   227.86  140.98   5.56     0   5606.99  65.95   \n",
              "7   ...   469.87   251.56   129.70   75.38   3.62     0   7610.61  36.85   \n",
              "8   ...   951.31   300.00   176.32   88.77   5.40     0   8586.62  65.98   \n",
              "9   ...   576.28   381.84   305.47   69.71   1.89     0   9412.12  65.85   \n",
              "10  ...   254.56   254.56   127.28  180.00   2.00     0   3782.68  65.65   \n",
              "11  ...  1127.70   649.00   331.59  185.94   3.40     0  13669.58  65.68   \n",
              "12  ...   790.57   360.56   218.54  103.73   3.62     0   3668.15  66.18   \n",
              "13  ...   900.00   400.00   275.00   69.13   3.27     0   4514.70  65.91   \n",
              "14  ...   649.00   127.28   106.07   51.96   6.12     1   8654.28  65.85   \n",
              "15  ...   768.96   284.60   170.58   61.45   4.51     0  22517.01  66.33   \n",
              "16  ...  2672.86   636.40   345.47  145.92   7.74     0  28174.27  65.92   \n",
              "17  ...     0.00     0.00     0.00    0.00   0.00     0   9122.65  36.86   \n",
              "18  ...   851.47   282.84   184.94   84.35   4.60     0  27836.68  65.77   \n",
              "19  ...  1049.57   127.28    25.46   53.67  41.23     1   2312.51  65.89   \n",
              "20  ...  1140.18    70.71    35.36   36.38  32.25     1   6946.12  65.67   \n",
              "21  ...   509.90   353.55   215.77   75.97   2.36     0   3664.41  66.33   \n",
              "22  ...   850.18   265.17    96.93   90.13   8.77     0  12460.92  36.64   \n",
              "23  ...   509.90   316.23   136.62   67.36   3.73     0  27403.81  66.16   \n",
              "24  ...  3447.10  1411.56   824.28  212.62   4.18     0   7016.73  65.80   \n",
              "\n",
              "     f_49  target  \n",
              "0    6.56       0  \n",
              "1    6.02       0  \n",
              "2    7.35       0  \n",
              "3    7.67       0  \n",
              "4    6.28       0  \n",
              "5    6.74       0  \n",
              "6    7.42       0  \n",
              "7   15.16       0  \n",
              "8    7.75       0  \n",
              "9    6.18       0  \n",
              "10   6.26       0  \n",
              "11   7.11       0  \n",
              "12   7.98       0  \n",
              "13   7.02       0  \n",
              "14   6.13       0  \n",
              "15   7.28       1  \n",
              "16   7.65       1  \n",
              "17  14.99       0  \n",
              "18   7.29       1  \n",
              "19   6.15       0  \n",
              "20   7.48       0  \n",
              "21   7.93       0  \n",
              "22  15.26       0  \n",
              "23   5.98       0  \n",
              "24   7.66       0  \n",
              "\n",
              "[25 rows x 50 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('oil_spill.csv')\n",
        "df = df.sample(frac = 1, random_state = 7).reset_index(drop = True)\n",
        "df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRjYEt_ZGjPZ"
      },
      "source": [
        "## --> Exploración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfyC3JIAGrhX",
        "outputId": "4b8bf8e3-621a-4ec6-8c34-daa9741f36f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(937, 50)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "oT2hsW2UGwpv",
        "outputId": "f4bb99d1-4572-40d4-9c77-45763131df47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    896\n",
              "1     41\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQw3L2XqHAn_",
        "outputId": "9808cbea-112e-476b-d8a0-0475f1b51003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IR: 21.853658536585368\n"
          ]
        }
      ],
      "source": [
        "clase_mayoritaria = df['target'].value_counts()[0]\n",
        "clase_minoritaria = df['target'].value_counts()[1]\n",
        "IR = clase_mayoritaria / clase_minoritaria\n",
        "print(f\"IR: {IR}\")\n",
        "# Es un conjunto de datos desbalanceado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRjQ589LQBV8"
      },
      "source": [
        "## Limpieza de repetidos e indiscernibles  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEXhRRx4QJb3",
        "outputId": "d7c98e60-d196-4946-d652-2a8794106181"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(937, 50)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ELiminar datos nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# Eliminar duplicados\n",
        "df = df.drop_duplicates(keep = 'first')\n",
        "\n",
        "# Eliminar indiscernibles\n",
        "caracteristicas = df.drop('target', axis = 1)\n",
        "df = df[~df.duplicated(subset = caracteristicas, keep = False)]\n",
        "\n",
        "df.shape\n",
        "# No tiene valores nulos, duplicados ni indiscernibles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1z-cbY-JtRl"
      },
      "source": [
        "## Creación de conjuntos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fEeiHybFJ4oN"
      },
      "outputs": [],
      "source": [
        "X = df.drop('target', axis = 1)\n",
        "Y = df['target']\n",
        "\n",
        "# Entrenamiento\n",
        "proporcion = 0.8\n",
        "\n",
        "x_train = X.iloc[:int(len(X) * proporcion), :] # --> Hasta el 0.8\n",
        "y_train = Y.iloc[:int(len(X) * proporcion)]\n",
        "\n",
        "# Prueba\n",
        "x_test = X.iloc[int(len(Y) * proporcion):, :] # --> Desde el 0.8\n",
        "y_test = Y.iloc[int(len(Y) * proporcion):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpkJnbyfKx2g",
        "outputId": "5fabb22b-915d-433e-bb9e-2c88bb3838b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y entrenamiento: target\n",
            "0    718\n",
            "1     31\n",
            "Name: count, dtype: int64\n",
            "Y prueba       : target\n",
            "0    178\n",
            "1     10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Y entrenamiento: {y_train.value_counts()}\")\n",
        "print(f\"Y prueba       : {y_test.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-krLki_38ZgZ",
        "outputId": "ce5aaac5-42cd-4c62-e828-53a66e7eb543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X entrenamiento: (749, 49)\n",
            "Y entrenamiento: (749,)\n",
            "X prueba: (188, 49)\n",
            "Y prueba: (188,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X entrenamiento: {x_train.shape}\")\n",
        "print(f\"Y entrenamiento: {y_train.shape}\")\n",
        "print(f\"X prueba: {x_test.shape}\")\n",
        "print(f\"Y prueba: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzmekewP6A4M"
      },
      "source": [
        "### Aplicar SMOTE en el conjunto de entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ji6iTEMI6Lgi"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state = 7)\n",
        "x_train, y_train = smote.fit_resample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPeCB2x88Jxs",
        "outputId": "1bc31f26-d572-4884-c41b-eafdaec30664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y entrenamiento: target\n",
            "0    718\n",
            "1    718\n",
            "Name: count, dtype: int64\n",
            "Y prueba       : target\n",
            "0    178\n",
            "1     10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Y entrenamiento: {y_train.value_counts()}\")\n",
        "print(f\"Y prueba       : {y_test.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohnPvXmoDvxr",
        "outputId": "6695e13c-2fb4-4c9d-b480-ec248605366c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X entrenamiento: (1436, 49)\n",
            "Y entrenamiento: (1436,)\n",
            "X prueba: (188, 49)\n",
            "Y prueba: (188,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X entrenamiento: {x_train.shape}\")\n",
        "print(f\"Y entrenamiento: {y_train.shape}\")\n",
        "print(f\"X prueba: {x_test.shape}\")\n",
        "print(f\"Y prueba: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhykRlAMM-J7"
      },
      "source": [
        "# Algoritmos Biclase\n",
        "* Euclidiano\n",
        "* 1NN\n",
        "* 3NN\n",
        "* 5NN\n",
        "* 7NN\n",
        "* IB1\n",
        "* IB3\n",
        "* IB5\n",
        "* IB7\n",
        "* Naive Bayes\n",
        "* Regresión logística\n",
        "* SVM\n",
        "* Árbol de desición\n",
        "* Random Forest\n",
        "* Red Neuronal\n",
        "\n",
        "Todos los algoritmos parten de una partición fija 80-20 con seed = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5ZZsDeJSR3d6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, recall_score, precision_score, f1_score,\n",
        "    matthews_corrcoef, balanced_accuracy_score, roc_auc_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SxLAZyvUVSPl"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "def calcula_medidas(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    error_rate = 1 - accuracy\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    specificity = recall_score(y_test, y_pred, pos_label = 0)\n",
        "    bacc = balanced_accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    metrics_table = [\n",
        "        ['Accuracy', accuracy],\n",
        "        ['Error Rate', error_rate],\n",
        "        ['Recall (Sensibilidad)', recall],\n",
        "        ['Specificity', specificity],\n",
        "        ['Balanced Accuracy', bacc],\n",
        "        ['Precision', precision],\n",
        "        ['F1 Score', f1],\n",
        "        ['MCC', mcc],\n",
        "        ['ROC AUC', roc]\n",
        "    ]\n",
        "    print(tabulate(metrics_table, headers = ['Métrica', 'Valor'], floatfmt = \".4f\", tablefmt = \"plain\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q_YGevbvmBW4"
      },
      "outputs": [],
      "source": [
        "def matriz(y_test, y_pred):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  print(\"-\"*30)\n",
        "  print(\"Matriz de confusión:\")\n",
        "  print(f\"{tp:>3} {fn:>3}\")\n",
        "  print(f\"{fp:>3} {tn:>3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytuH7o_RyxD"
      },
      "source": [
        "### Algoritmo Euclidiano\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asSo6UvpUm3B",
        "outputId": "98f9a608-cde6-441c-cc5a-44b7b11cf73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8245\n",
            "Error Rate              0.1755\n",
            "Recall (Sensibilidad)   0.5000\n",
            "Specificity             0.8427\n",
            "Balanced Accuracy       0.6713\n",
            "Precision               0.1515\n",
            "F1 Score                0.2326\n",
            "MCC                     0.2022\n",
            "ROC AUC                 0.6713\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  5   5\n",
            " 28 150\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "KNN = KNeighborsClassifier(n_neighbors = 1, metric = 'euclidean')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4IMdgaXfshq"
      },
      "source": [
        "### Algoritmo 1NN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIxEK2PkfyIT",
        "outputId": "30b65e08-039c-423f-c807-f0b8014d564a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8298\n",
            "Error Rate              0.1702\n",
            "Recall (Sensibilidad)   0.5000\n",
            "Specificity             0.8483\n",
            "Balanced Accuracy       0.6742\n",
            "Precision               0.1562\n",
            "F1 Score                0.2381\n",
            "MCC                     0.2080\n",
            "ROC AUC                 0.6742\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  5   5\n",
            " 27 151\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 1, metric = 'chebyshev')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-HCUcJPhHAA"
      },
      "source": [
        "### Algoritmo 3NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCYKkEnFhc7m",
        "outputId": "5765eaab-16a6-4df1-db05-b8e3fcb3a295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8298\n",
            "Error Rate              0.1702\n",
            "Recall (Sensibilidad)   0.8000\n",
            "Specificity             0.8315\n",
            "Balanced Accuracy       0.8157\n",
            "Precision               0.2105\n",
            "F1 Score                0.3333\n",
            "MCC                     0.3529\n",
            "ROC AUC                 0.8157\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  8   2\n",
            " 30 148\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 3, metric = 'chebyshev')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vc6bo6JhnyV"
      },
      "source": [
        "### Algoritmo 5NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dkJaP_chqPB",
        "outputId": "5866aa2c-c517-4236-fdff-7d905ddf25ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8191\n",
            "Error Rate              0.1809\n",
            "Recall (Sensibilidad)   0.6000\n",
            "Specificity             0.8315\n",
            "Balanced Accuracy       0.7157\n",
            "Precision               0.1667\n",
            "F1 Score                0.2609\n",
            "MCC                     0.2461\n",
            "ROC AUC                 0.7157\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  6   4\n",
            " 30 148\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'chebyshev')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCM30H_biH_G"
      },
      "source": [
        "### Algoritmo 7NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_ZJomfUiKU0",
        "outputId": "0f85fdfc-62df-4f12-aaea-13f473afc187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8245\n",
            "Error Rate              0.1755\n",
            "Recall (Sensibilidad)   0.7000\n",
            "Specificity             0.8315\n",
            "Balanced Accuracy       0.7657\n",
            "Precision               0.1892\n",
            "F1 Score                0.2979\n",
            "MCC                     0.3000\n",
            "ROC AUC                 0.7657\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  7   3\n",
            " 30 148\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 7, metric = 'chebyshev')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB16Q6S-iUGB"
      },
      "source": [
        "### Algoritmo IB1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728uGiRSiaG-",
        "outputId": "df49e42e-fa13-4e53-9946-c6c859765c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8617\n",
            "Error Rate              0.1383\n",
            "Recall (Sensibilidad)   0.5000\n",
            "Specificity             0.8820\n",
            "Balanced Accuracy       0.6910\n",
            "Precision               0.1923\n",
            "F1 Score                0.2778\n",
            "MCC                     0.2483\n",
            "ROC AUC                 0.6910\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  5   5\n",
            " 21 157\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 1, metric = 'manhattan')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX6YhCNgmqSU"
      },
      "source": [
        "### Algoritmo IB3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_uw91gTms5Q",
        "outputId": "aee773f4-773c-4774-ee92-dda05c68f7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8670\n",
            "Error Rate              0.1330\n",
            "Recall (Sensibilidad)   0.8000\n",
            "Specificity             0.8708\n",
            "Balanced Accuracy       0.8354\n",
            "Precision               0.2581\n",
            "F1 Score                0.3902\n",
            "MCC                     0.4057\n",
            "ROC AUC                 0.8354\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  8   2\n",
            " 23 155\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 3, metric = 'manhattan')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIVVlPOVnXmT"
      },
      "source": [
        "### Algoritmo IB5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbj0FzJGngap",
        "outputId": "64abc29d-102a-46cd-e785-fadcefa0c227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8564\n",
            "Error Rate              0.1436\n",
            "Recall (Sensibilidad)   0.7000\n",
            "Specificity             0.8652\n",
            "Balanced Accuracy       0.7826\n",
            "Precision               0.2258\n",
            "F1 Score                0.3415\n",
            "MCC                     0.3418\n",
            "ROC AUC                 0.7826\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  7   3\n",
            " 24 154\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'manhattan')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjIoF_CInrqE"
      },
      "source": [
        "### Algoritmo IB7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXqfCCDGntsA",
        "outputId": "2e45eeaf-4fdb-4684-e03d-1577d2f4ce9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8457\n",
            "Error Rate              0.1543\n",
            "Recall (Sensibilidad)   0.7000\n",
            "Specificity             0.8539\n",
            "Balanced Accuracy       0.7770\n",
            "Precision               0.2121\n",
            "F1 Score                0.3256\n",
            "MCC                     0.3268\n",
            "ROC AUC                 0.7770\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  7   3\n",
            " 26 152\n"
          ]
        }
      ],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors = 7, metric = 'manhattan')\n",
        "KNN.fit(x_train, y_train)\n",
        "y_pred = KNN.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_0DmPm8oAxu"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVwjNRRjoD2z",
        "outputId": "ccbb4009-b6f7-4e83-fa90-a092bdcb715e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.2819\n",
            "Error Rate              0.7181\n",
            "Recall (Sensibilidad)   0.7000\n",
            "Specificity             0.2584\n",
            "Balanced Accuracy       0.4792\n",
            "Precision               0.0504\n",
            "F1 Score                0.0940\n",
            "MCC                    -0.0213\n",
            "ROC AUC                 0.4792\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  7   3\n",
            "132  46\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "NB = GaussianNB()\n",
        "NB.fit(x_train, y_train)\n",
        "y_pred = NB.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrUx6lqQo6-D"
      },
      "source": [
        "### Regresión Logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZTNEI4bo-cA",
        "outputId": "e3f8f3db-5ce1-4f3d-9672-8cb8f5e4e4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.9043\n",
            "Error Rate              0.0957\n",
            "Recall (Sensibilidad)   0.7000\n",
            "Specificity             0.9157\n",
            "Balanced Accuracy       0.8079\n",
            "Precision               0.3182\n",
            "F1 Score                0.4375\n",
            "MCC                     0.4299\n",
            "ROC AUC                 0.8079\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  7   3\n",
            " 15 163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jair/anaconda3/envs/CIP/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(x_train, y_train)\n",
        "y_pred = LR.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX0ZFk-7qAMh"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us_FwqzPqDM0",
        "outputId": "adcf3e6e-8347-4427-afe6-7ae0bfc1f330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.8670\n",
            "Error Rate              0.1330\n",
            "Recall (Sensibilidad)   0.4000\n",
            "Specificity             0.8933\n",
            "Balanced Accuracy       0.6466\n",
            "Precision               0.1739\n",
            "F1 Score                0.2424\n",
            "MCC                     0.2008\n",
            "ROC AUC                 0.6466\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  4   6\n",
            " 19 159\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(x_train, y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUm5ODM1q_rH"
      },
      "source": [
        "### Árbol de desición"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NzgD0owrEpO",
        "outputId": "7693b7d8-343c-4ce6-fb78-4e50d7ef7c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.9309\n",
            "Error Rate              0.0691\n",
            "Recall (Sensibilidad)   0.2000\n",
            "Specificity             0.9719\n",
            "Balanced Accuracy       0.5860\n",
            "Precision               0.2857\n",
            "F1 Score                0.2353\n",
            "MCC                     0.2038\n",
            "ROC AUC                 0.5860\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  2   8\n",
            "  5 173\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(x_train, y_train)\n",
        "y_pred = DT.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nj9Zx_Gro2g"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4QfpykrsJX",
        "outputId": "50562878-e34c-41e4-b133-0cb3da266bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métrica                  Valor\n",
            "Accuracy                0.9787\n",
            "Error Rate              0.0213\n",
            "Recall (Sensibilidad)   0.6000\n",
            "Specificity             1.0000\n",
            "Balanced Accuracy       0.8000\n",
            "Precision               1.0000\n",
            "F1 Score                0.7500\n",
            "MCC                     0.7660\n",
            "ROC AUC                 0.8000\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  6   4\n",
            "  0 178\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier()\n",
        "RF.fit(x_train, y_train)\n",
        "y_pred = RF.predict(x_test)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45eis99t2KtO"
      },
      "source": [
        "### Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vbKljaHGehR",
        "outputId": "d392e5d7-8c32-41df-fc18-084e5b9c566c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-14 00:21:44.935571: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-14 00:21:44.936128: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-14 00:21:44.938667: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-14 00:21:44.946453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749882104.959137    5121 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749882104.962943    5121 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749882104.971331    5121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749882104.971345    5121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749882104.971347    5121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749882104.971348    5121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-14 00:21:44.976591: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/jair/anaconda3/envs/CIP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-06-14 00:21:46.463825: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "Métrica                  Valor\n",
            "Accuracy                0.9149\n",
            "Error Rate              0.0851\n",
            "Recall (Sensibilidad)   0.6000\n",
            "Specificity             0.9326\n",
            "Balanced Accuracy       0.7663\n",
            "Precision               0.3333\n",
            "F1 Score                0.4286\n",
            "MCC                     0.4062\n",
            "ROC AUC                 0.7663\n",
            "------------------------------\n",
            "Matriz de confusión:\n",
            "  6   4\n",
            " 12 166\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "import numpy as np\n",
        "\n",
        "# Establecer semilla\n",
        "SEED = 7\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(21, activation='relu', input_shape=(x_train.shape[1],), kernel_initializer=HeNormal(seed=SEED)),\n",
        "    Dense(33, activation='relu', kernel_initializer=HeNormal(seed=SEED)),\n",
        "    Dense(1, activation='sigmoid')  # Salida binaria\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "y_prob = model.predict(x_test).ravel()\n",
        "y_pred = (y_prob >= 0.30).astype(int)\n",
        "\n",
        "calcula_medidas(y_test, y_pred)\n",
        "matriz(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9QVGs5oAKG2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CIP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
